{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### **Transform Team Dimension**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "%run /utils/general_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "create_mounts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "job_id = mssparkutils.env.getJobId()\r\n",
        "\r\n",
        "team_df = spark.read.format('delta').load(f'synfs:/{job_id}/mnt/silver/dim_team')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql.functions import when, col\r\n",
        "\r\n",
        "team_final_df = team_df.withColumn('abbreviation', when(col('abbreviation').isNull(), 'N/a').otherwise(col('abbreviation'))) \\\r\n",
        "    .withColumn('city', when(col('city').isNull(), 'N/a').otherwise(col('city'))) \\\r\n",
        "    .withColumn('conference', when(col('conference').isNull(), 'N/a').otherwise(col('conference'))) \\\r\n",
        "    .withColumn('division', when(col('division').isNull(), 'N/a').otherwise(col('division'))) \\\r\n",
        "    .withColumn('full_name', when(col('full_name').isNull(), 'N/a').otherwise(col('full_name'))) \\\r\n",
        "    .withColumn('name', when(col('name').isNull(), 'N/a').otherwise(col('name'))) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Merge Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "container = 'gold'\r\n",
        "database = 'prize_picks_gold'\r\n",
        "table = 'dim_team'\r\n",
        "file_format = 'delta'\r\n",
        "merge_condition = 'tgt.team_key = src.team_key'\r\n",
        "\r\n",
        "merge_data(team_final_df, container, database, table, file_format, merge_condition=merge_condition )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        }
      },
      "source": [
        "%%sql\r\n",
        "DROP TABLE IF EXISTS prize_picks_silver.dim_team;"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}