{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### **Ingest Teams JSON**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Configuaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "%run /utils/general_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "create_mounts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Define Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, TimestampType\r\n",
        "\r\n",
        "teams_schema = StructType([\r\n",
        "    StructField('id', IntegerType(), False),\r\n",
        "    StructField('abbreviation', StringType(), True),\r\n",
        "    StructField('city', StringType(), True),\r\n",
        "    StructField('conference', StringType(), True),\r\n",
        "    StructField('division', StringType(), True),\r\n",
        "    StructField('full_name', StringType(), True),\r\n",
        "    StructField('name', StringType(), True)\r\n",
        "])\r\n",
        "\r\n",
        "teams_gold_schema = StructType([\r\n",
        "    StructField('id', IntegerType(), False),\r\n",
        "    StructField('abbreviation', StringType(), True),\r\n",
        "    StructField('city', StringType(), True),\r\n",
        "    StructField('conference', StringType(), True),\r\n",
        "    StructField('division', StringType(), True),\r\n",
        "    StructField('full_name', StringType(), True),\r\n",
        "    StructField('name', StringType(), True),\r\n",
        "    StructField('is_active', BooleanType(), True),\r\n",
        "    StructField('eff_start_date', TimestampType(), True),\r\n",
        "    StructField('eff_end_date', TimestampType(), True),\r\n",
        "    StructField('team_key', IntegerType(), True)\r\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Read Teams File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "job_id = mssparkutils.env.getJobId()\r\n",
        "\r\n",
        "# Teams in gold container\r\n",
        "teams_gold_df = None\r\n",
        "\r\n",
        "# Teams in bronze container\r\n",
        "teams_df = spark.read.json(f'synfs:/{job_id}/mnt/bronze/teams/teams.json', teams_schema)\r\n",
        "\r\n",
        "for table in spark.catalog.listTables('prize_picks_gold'):\r\n",
        "    if table.name == 'dim_team':\r\n",
        "        teams_gold_df = spark.read.format('delta').load(f'synfs:/{job_id}/mnt/gold/dim_team')\r\n",
        "    else:\r\n",
        "        teams_gold_df = spark.createDataFrame([], teams_gold_schema)\r\n",
        "\r\n",
        "# New teams\r\n",
        "teams_diff_df = teams_df.exceptAll(teams_gold_df.drop('is_active').drop('eff_start_date').drop('eff_end_date').drop('team_key'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Get Max team_key From Gold Container"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "from pyspark.sql.functions import max\r\n",
        "\r\n",
        "max_value = None\r\n",
        "\r\n",
        "if teams_gold_df.count() > 0:\r\n",
        "    max_value_df = teams_gold_df.agg(max(teams_gold_df.team_key))\r\n",
        "    max_value = max_value_df.collect()[0][0]\r\n",
        "\r\n",
        "max_team_key = max_value if max_value is not None else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Add Date and key attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "from pyspark.sql.functions import lit, row_number, current_timestamp\r\n",
        "from pyspark.sql import Window\r\n",
        "\r\n",
        "teams_diff_updated_df = None\r\n",
        "spec = Window.orderBy(teams_diff_df.full_name.asc())\r\n",
        "\r\n",
        "teams_diff_updated_df = teams_diff_df \\\r\n",
        "    .withColumn('is_active', lit(True)) \\\r\n",
        "    .withColumn('eff_start_date', current_timestamp()) \\\r\n",
        "    .withColumn('eff_end_date', lit('1900-01-01 00:00:00.000').cast('timestamp')) \\\r\n",
        "    .withColumn('team_key', row_number().over(spec) + max_team_key)\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "teams_gold_df = teams_gold_df.withColumnRenamed('team_id', 'id')\r\n",
        "\r\n",
        "combined_teams_df = teams_gold_df.unionByName(teams_diff_updated_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "max_date_df = combined_teams_df.groupBy(combined_teams_df.id.alias('groupby_id')) \\\r\n",
        "    .agg(max(combined_teams_df.eff_start_date).alias('max_date')) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Mark Rows With A Dimension Change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "teams_scd_df = combined_teams_df.join(max_date_df, (combined_teams_df.id == max_date_df.groupby_id) & (combined_teams_df.eff_start_date == max_date_df.max_date), 'left') \\\r\n",
        "    .drop(max_date_df.groupby_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Update Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql.functions import when, col \r\n",
        "\r\n",
        "teams_final_df = teams_scd_df.withColumnRenamed('id', 'team_id') \\\r\n",
        "    .withColumn('is_active', when(col('max_date').isNull(), lit(False)).otherwise(col('is_active'))) \\\r\n",
        "    .withColumn('eff_end_date', when(col('max_date').isNull(), current_timestamp()).otherwise(col('eff_end_date'))) \\\r\n",
        "    .drop('max_date')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Write file as table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        }
      },
      "source": [
        "%%sql\r\n",
        "DROP TABLE IF EXISTS prize_picks_silver.dim_team;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "container = 'silver'\r\n",
        "database = 'prize_picks_silver'\r\n",
        "table = 'dim_team'\r\n",
        "file_format = 'delta'\r\n",
        "merge_condition = 'tgt.team_key == src.team_key'\r\n",
        "\r\n",
        "merge_data(teams_final_df, container, database, table, file_format, merge_condition=merge_condition)"
      ]
    }
  ]
}