{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import delta\r\n",
        "\r\n",
        "def merge_data(input_df, container, database, table, file_format, partition_col = None, merge_condition = ''):\r\n",
        "    tables = [db_table.name for db_table in spark.catalog.listTables(database)]\r\n",
        "     \r\n",
        "    if table in tables:\r\n",
        "        delta_table = delta.DeltaTable.forPath(spark, f'synfs:/{job_id}/mnt/{container}/{table}')\r\n",
        "\r\n",
        "        delta_table.alias('tgt') \\\r\n",
        "            .merge(\r\n",
        "                input_df.alias('src'),\r\n",
        "                merge_condition\r\n",
        "            ) \\\r\n",
        "            .whenMatchedUpdateAll() \\\r\n",
        "            .whenNotMatchedInsertAll() \\\r\n",
        "            .execute()\r\n",
        "    else:\r\n",
        "        if partition_col is None:\r\n",
        "            input_df.write \\\r\n",
        "                .mode('overwrite') \\\r\n",
        "                .format(file_format) \\\r\n",
        "                .saveAsTable(f'{database}.{table}')\r\n",
        "        else:\r\n",
        "            input_df.write \\\r\n",
        "                .mode('overwrite') \\\r\n",
        "                .format(file_format) \\\r\n",
        "                .partitionBy(partition_col) \\\r\n",
        "                .saveAsTable(f'{database}.{table}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def create_mounts():\r\n",
        "    containers = ['bronze', 'silver', 'gold']\r\n",
        "    mounts = mssparkutils.fs.mounts()\r\n",
        "\r\n",
        "    \r\n",
        "    for container in containers:\r\n",
        "        mount_point = '/mnt/' + container\r\n",
        "        mount_exists = any(mount.mountPoint == mount_point for mount in mounts)\r\n",
        "\r\n",
        "        if not mount_exists:\r\n",
        "            mssparkutils.fs.mount( \r\n",
        "            f'abfss://{container}@prizepicksnba.dfs.core.windows.net', \r\n",
        "            f'/mnt/{container}', \r\n",
        "            {'LinkedService': 'ls_adls_prizepicksnba'} \r\n",
        ") "
      ]
    }
  ]
}